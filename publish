#!/usr/bin/env python3
from getpass import getpass
from pathlib import Path
import hashlib
import argparse
import json
import requests


IGNORE = ['.git']

USER_NAME = 'old-castle-fansubs'
ALLOWED_FILETYPES = [
    '.html', '.htm',
    '.jpg', '.png', '.gif', '.svg', '.ico',
    '.js', '.css',
    '.txt', '.ass',
]


def collect_local_files(local_root):
    for path in local_root.iterdir():
        if path.name in IGNORE:
            continue
        elif path.is_file():
            if path.suffix in ALLOWED_FILETYPES:
                yield path
        elif path.is_dir():
            yield from collect_local_files(path)


def get_local_info(local_paths):
    return {
        path: hashlib.md5(path.read_bytes()).hexdigest()
        for path in local_paths
    }


def get_remote_info(published_path):
    if not published_path.exists():
        return {}
    return {
        Path(path): checksum
        for path, checksum in json.loads(published_path.read_text()).items()
    }


def save_remote_info(published_path, info):
    published_path.write_text(json.dumps({
        str(path): checksum
        for path, checksum in info.items()
    }))


def collect_diff(local_info, remote_info):
    local_paths = set(local_info.keys())
    remote_paths = set(remote_info.keys())

    files_to_create = local_paths - remote_paths
    files_to_delete = remote_paths - local_paths
    files_to_update = set(
        path
        for path in local_paths & remote_paths
        if local_info[path] != remote_info[path])

    return files_to_create, files_to_update, files_to_delete


def sync_files(base_url, local_root, files_to_upload, files_to_delete):
    if files_to_delete:
        for path in sorted(files_to_delete):
            print(f'Removing {path}')
        if base_url:
            response = requests.post(
                f'{base_url}/delete', params={'filenames[]': files_to_delete})
            response.raise_for_status()

    if files_to_upload:
        for path in sorted(files_to_upload):
            print(f'Uploading {path}')
            files = {str(path.relative_to(local_root)): path.open(mode='rb')}
            if base_url:
                response = requests.post(f'{base_url}/upload', files=files)
                response.raise_for_status()


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('-d', '--dry-run', action='store_true')
    return parser.parse_args()


def main():
    args = parse_args()
    dry_run = args.dry_run

    local_root = Path(__file__).parent / 'public'
    published_path = Path(__file__).parent / '.publish.json'

    local_files = list(collect_local_files(local_root))
    local_info = get_local_info(local_files)
    remote_info = get_remote_info(published_path)

    files_to_create, \
    files_to_update, \
    files_to_delete = collect_diff(local_info, remote_info)
    files_to_upload = files_to_update | files_to_create

    if not files_to_upload and not files_to_delete:
        print('Nothing to do')
        return

    if dry_run:
        base_url = None
    else:
        password = getpass('Password: ')
        base_url = f'https://{USER_NAME}:{password}@neocities.org/api'

    sync_files(base_url, local_root, files_to_upload, files_to_delete)

    if not dry_run:
        save_remote_info(published_path, local_info)


if __name__ == '__main__':
    main()
